# AI Video Transcript

A simple Python project that transcribes videos into text using [OpenAI Whisper](https://github.com/openai/whisper).

## ğŸ“‚ Project structure

```
ai-video-transcript/
â”‚
â”œâ”€â”€ app.py            # main script for transcription
â”œâ”€â”€ transcripts/      # generated text transcripts
â”œâ”€â”€ videos/           # input video files
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§  Instructions

```bash
# 1. Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 2. Install dependencies
python3 -m pip install --upgrade pip
pip3 install -r requirements.txt --break-system-packages
brew install ffmpeg

# 3. Add your video file
# Place your video in the "videos" folder (e.g., videos/all-info.MOV)

# 4. Run transcription
python3 app.py

# 5. Check output
# The transcript will be saved in the "transcripts" folder as a .txt file
```

---

## ğŸ“¦ requirements.txt

```txt
openai-whisper
```

*(Optional â€” you can generate this automatically with `pip freeze > requirements.txt`)*

---

## ğŸ”§ Features

Whisper can be used for more than just video-to-text transcription:

* Transcription â†’ Convert audio files (mp3, wav, m4a, etc.) into text.
* Translation â†’ Translate non-English speech directly into English text.
* Subtitles â†’ Generate `.srt` or `.vtt` subtitle files from videos.
* Voice Notes â†’ Turn recorded voice memos into searchable text.
* Meetings & Lectures â†’ Automatically transcribe recordings.
* Multilingual Audio â†’ Recognize and transcribe speech in many languages.

---

## ğŸŒ More AI Projects

* [Coqui TTS](https://github.com/coqui-ai/TTS) â†’ Text-to-speech for natural voices.
* [Riffusion](https://github.com/riffusion/riffusion-hobby) â†’ Real-time music generation with diffusion models.
* [Stable Diffusion](https://github.com/CompVis/stable-diffusion) â†’ High-quality image generation with text prompts.